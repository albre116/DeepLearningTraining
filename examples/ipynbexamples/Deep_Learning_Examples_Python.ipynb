{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast AI Examples of State of the Art Deep Learning (www.fast.ai.com)\n",
    "- Source code and build instructions you are seeing right now are here at https://github.com/albre116/DeepLearningTraining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Deep Learning?\n",
    "![Deep Net](images/main-qimg-33480ff9bf380946b73b0b7448429d20.webp)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![AI explained](images/main-qimg-8ac214180be0945faa6774bdb851d8a2.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Its a More sophisticated Data Science tool than Classical Machine Learning\n",
    "- Learns complex patterns in high dimension that lead to Outcomes versus trying to find decision boundaries based upon a handful of pre-engineered features\n",
    "- Acts like a human brain and looks for information consistency and weighs a large number of possible considerations in formulating a complex judgement\n",
    "- Uses GPU's to perform Gradient Descent (a High-Dimensional series of small improvements... just like insect colony intelligence)\n",
    "- Like teaching a child to read, however, you need a lot of books to have any chance of success (i.e. training data)\n",
    "\n",
    "# MNIST Digit Challenge\n",
    "![MINST](images/mnistExamples.png)\n",
    "\n",
    "\n",
    "## [Results ML versus DL Algorithms](http://yann.lecun.com/exdb/mnist/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle is Gold Standard and Uses Are Vast\n",
    "- Machine Vision\n",
    "- Natural Language Understanding, Natural Language Generation\n",
    "- Recommender Systems\n",
    "- Market Segmentation\n",
    "- Memory Intensive Applications (i.e. tricky time series)\n",
    "- Reinforcement Learning (Robot Traders, Drones, Self-Driving Cars, Video Games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1:  Machine Vision Typical Setup\n",
    "![books](images/books-3.jpg)\n",
    "\n",
    "![poor](images/no-knowledge.jpeg)\n",
    "\n",
    "- ### You are a person who doesn't have a library of your own, you only have a couple of random medical books and you don't know how to read\n",
    "- ### You need to be get some information from these books to make medicine but you don't have enough books to learn how to read\n",
    "- ### What do you do?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duh, You Bring Someone Over Who Owns a Library and Can Read for You\n",
    "![library](images/1200px-Melk_-_Abbey_-_Library.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We do the exact same thing for Machine Vision\n",
    "- ## Go Get a Pretrained net that can see\n",
    "- ## Lop the head off the net which controls the final behavior\n",
    "- ## Reconnect that final layer for the task at hand\n",
    "\n",
    "![original image](https://image.slidesharecdn.com/practicaldeeplearning-160329181459/95/practical-deep-learning-16-638.jpg)\n",
    "\n",
    "## [imagenetdog](http://www.image-net.org/synset?wnid=n02098906)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just like Reading, Vision is Based Upon Generalizable Learnings Applied to A Final Task\n",
    "\n",
    "![machinevision](images/Hl2H6.png)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Applications of Machine Vision Are Vast @ Robinson\n",
    "### Can you think of a Few?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets go ahead and build a dogs versus cats classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###code starts here\n",
    "\n",
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# This file contains all the main external libs we'll use\n",
    "from fastai.imports import *\n",
    "\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *\n",
    "\n",
    "\n",
    "PATH = \"/notebooks/courses/dl1/data/dogscats/\"\n",
    "sz=224\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.cudnn.enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###lets pull an image in the vaildation file we will try to predict\n",
    "files = os.listdir(f'{PATH}valid/cats')[:5]\n",
    "img = plt.imread(f'{PATH}valid/cats/{files[0]}')\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###lets pull an image in the vaildation file we will try to predict\n",
    "files = os.listdir(f'{PATH}valid/dogs')[:5]\n",
    "img = plt.imread(f'{PATH}valid/dogs/{files[0]}')\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We Split our Data Into Train, Validation, and Test Sets Prior to Modeling\n",
    "### Why Don't We Fit the Model on All of the Data?\n",
    "![](images/traintest.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###what does that look like to a computer?\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[:4,:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our first model: quick start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use a <b>pre-trained</b> model, that is, a model created by some one else to solve a different problem. Instead of building a model from scratch to solve a similar problem, we'll use a model trained on ImageNet (1.2 million images and 1000 classes) as a starting point. The model is a Convolutional Neural Network (CNN), a type of Neural Network that builds state-of-the-art models for computer vision. We'll be learning all about CNNs during this course.\n",
    "\n",
    "We will be using the <b>resnet34</b> model. resnet34 is a version of the model that won the 2015 ImageNet competition. Here is more info on [resnet models](https://github.com/KaimingHe/deep-residual-networks). We'll be studying them in depth later, but for now we'll focus on using them effectively.\n",
    "\n",
    "Here's how to train and evalulate a *dogs vs cats* model in 3 lines of code, and under 20 seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch=resnet34\n",
    "data = ImageClassifierData.from_paths(PATH, tfms=tfms_from_model(arch, sz))\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=True)\n",
    "learn.fit(0.01, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is this model? Well, as we mentioned, prior to this competition, the state of the art was 80% accuracy. But the competition resulted in a huge jump to 98.9% accuracy, with the author of a popular deep learning library winning the competition. Extraordinarily, less than 4 years later, we can now beat that result in seconds! Even last year in this same course, our initial model had 98.3% accuracy, which is nearly double the error we're getting just a year later, and that took around 10 minutes to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing results: looking at pictures in validation data\n",
    "\n",
    "As well as looking at the overall metrics, it's also a good idea to look at examples of each of:\n",
    "1. A few correct labels at random\n",
    "2. A few incorrect labels at random\n",
    "3. The most correct labels of each class (ie those with highest probability that are correct)\n",
    "4. The most incorrect labels of each class (ie those with highest probability that are incorrect)\n",
    "5. The most uncertain labels (ie those with probability closest to 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the label for a val data\n",
    "data.val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from here we know that 'cats' is label 0 and 'dogs' is label 1.\n",
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this gives prediction for validation set. Predictions are in log scale\n",
    "log_preds = learn.predict()\n",
    "log_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(log_preds, axis=1)  # from log probabilities to 0 or 1\n",
    "probs = np.exp(log_preds[:,1])        # pr(dog)\n",
    "\n",
    "def rand_by_mask(mask): return np.random.choice(np.where(mask)[0], 4, replace=False)\n",
    "def rand_by_correct(is_correct): return rand_by_mask((preds == data.val_y)==is_correct)\n",
    "\n",
    "def plot_val_with_title(idxs, title):\n",
    "    imgs = np.stack([data.val_ds[x][0] for x in idxs])\n",
    "    title_probs = [probs[x] for x in idxs]\n",
    "    print(title)\n",
    "    return plots(data.val_ds.denorm(imgs), rows=1, titles=title_probs)\n",
    "\n",
    "def plots(ims, figsize=(12,6), rows=1, titles=None):\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None: sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i])\n",
    "        \n",
    "def load_img_id(ds, idx): return np.array(PIL.Image.open(PATH+ds.fnames[idx]))\n",
    "\n",
    "def plot_val_with_title(idxs, title):\n",
    "    imgs = [load_img_id(data.val_ds,x) for x in idxs]\n",
    "    title_probs = [probs[x] for x in idxs]\n",
    "    print(title)\n",
    "    return plots(imgs, rows=1, titles=title_probs, figsize=(16,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. A few correct labels at random\n",
    "plot_val_with_title(rand_by_correct(True), \"Correctly classified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. A few incorrect labels at random\n",
    "plot_val_with_title(rand_by_correct(False), \"Incorrectly classified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_by_mask(mask, mult):\n",
    "    idxs = np.where(mask)[0]\n",
    "    return idxs[np.argsort(mult * probs[idxs])[:4]]\n",
    "\n",
    "def most_by_correct(y, is_correct): \n",
    "    mult = -1 if (y==1)==is_correct else 1\n",
    "    return most_by_mask(((preds == data.val_y)==is_correct) & (data.val_y == y), mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(0, True), \"Most correct cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(1, True), \"Most correct dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(0, False), \"Most incorrect cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(1, False), \"Most incorrect dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_uncertain = np.argsort(np.abs(probs -0.5))[:4]\n",
    "plot_val_with_title(most_uncertain, \"Most uncertain predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2 IMDB Sentiment and Language Modeling\n",
    "- ### First we teach a deep net to predict the next word in a sentence using a trick called embedding\n",
    "- ### Then we take that net that can model language and connect it to feed a review model on sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [large movie view dataset](http://ai.stanford.edu/~amaas/data/sentiment/) contains a collection of 50,000 reviews from IMDB. The dataset contains an even number of positive and negative reviews. The authors considered only highly polarized reviews. A negative review has a score ≤ 4 out of 10, and a positive review has a score ≥ 7 out of 10. Neutral reviews are not included in the dataset. The dataset is divided into training and test sets. The training set is the same 25,000 labeled reviews.\n",
    "\n",
    "The **sentiment classification task** consists of predicting the polarity (positive or negative) of a given text.\n",
    "\n",
    "However, before we try to classify *sentiment*, we will simply try to create a *language model*; that is, a model that can predict the next word in a sentence. Why? Because our model first needs to understand the structure of English, before we can expect it to recognize positive vs negative sentiment.\n",
    "\n",
    "So our plan of attack is the same as we used for Dogs v Cats: pretrain a model to do one thing (predict the next word), and fine tune it to do something else (classify sentiment).\n",
    "\n",
    "Unfortunately, there are no good pretrained language models available to download, so we need to create our own. To follow along with this notebook, we suggest downloading the dataset from [this location](http://files.fast.ai/data/aclImdb.tgz) on files.fast.ai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.learner import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as pickle\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -rf data/aclImdb/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='data/aclImdb/'\n",
    "#os.mkdir(f'{PATH}models')\n",
    "\n",
    "TRN_PATH = 'train/all/'\n",
    "VAL_PATH = 'test/all/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "%ls {PATH}\n",
    "\n",
    "trn_files = !ls {TRN}\n",
    "trn_files[:10]\n",
    "review = !cat {TRN}{trn_files[0]}\n",
    "review[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We tokenize the text\n",
    "- ### map words to integers so computer can understand them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###This is going to be complicated, but i'll do my best\n",
    "###First we tokenize to something the computer can read\n",
    "#!python -m spacy download en\n",
    "spacy_tok = spacy.load('en')\n",
    "TEXT = data.Field(lower=True, tokenize=\"spacy\")\n",
    "###save the model\n",
    "#pickle.dump(TEXT, open(f'{PATH}models/TEXT.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the start of the mapping from integer IDs to unique tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Warning takes a long time\n",
    "bs=64; bptt=70\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We also clip up the reviews into sentences of Approx Length\n",
    "- ### Pass sentences into the model of length of about 70 words\n",
    "- ### Train the model to figure out the next word based upon the past 70 words\n",
    "![sentence clipping](images/matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model to Predict Next Word\n",
    "- ### Men are from Mars, Women are from <_____>?\n",
    "- ### The Sun Felt <____>?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "fastai uses a variant of the state of the art [AWD LSTM Language Model](https://arxiv.org/abs/1708.02182) developed by Stephen Merity. A key feature of this model is that it provides excellent regularization through [Dropout](https://en.wikipedia.org/wiki/Convolutional_neural_network#Dropout). There is no simple way known (yet!) to find the best values of the dropout parameters below - you just have to experiment...\n",
    "\n",
    "However, the other parameters (`alpha`, `beta`, and `clip`) shouldn't generally need tuning.\n",
    "\n",
    "For the model the critical things is we do an embedding in combination with a LSTM time series model\n",
    "![seaworld](images/embed2.webp)\n",
    "<br>\n",
    "<br>\n",
    "![embedconcept](images/embedword.png)\n",
    "<br>\n",
    "<br>\n",
    "#### Our Goal is to learn this embedding structure so we can later feed it into the net\n",
    "<br>\n",
    "<br>\n",
    "![netarch](images/embed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets take a peek at the model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'stoi': 'string to int'\n",
    "TEXT.vocab.stoi['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'itos': 'int-to-string'\n",
    "TEXT.vocab.itos[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the: # batches; # unique tokens in the vocab; # tokens in the training set; # sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(md.trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz = 200  # size of each embedding vector\n",
    "nh = 500     # number of hidden activations per layer\n",
    "nl = 3       # number of layers\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n",
    "learner = md.get_model(opt_fn, em_sz, nh, nl,\n",
    "               dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner.clip=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=1,cycle_save_name='adam1')\n",
    "learner.save_encoder('adam1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(3e-3, 1, wds=1e-6, cycle_len=1, \n",
    "            cycle_save_name='adam3_20')\n",
    "learner.save_encoder('adam3_20_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_cycle('adam3_20',0)\n",
    "learner.load_encoder('adam3_20_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(TEXT, open(f'{PATH}models/TEXT.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can play around with our language model a bit to check it seems to be working OK. First, let's create a short bit of text to 'prime' a set of predictions. We'll use our torchtext field to numericalize it so we can feed it to our language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=learner.model\n",
    "ss=\"\"\". So, it wasn't quite was I was expecting, but I really liked it anyway! The best movie\"\"\"\n",
    "s = [sent.string.strip() for sent in spacy_tok(ss)]\n",
    "t=TEXT.numericalize([s])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size to 1\n",
    "m[0].bs=1\n",
    "# Turn off dropout\n",
    "m.eval()\n",
    "# Reset hidden state\n",
    "m.reset()\n",
    "# Get predictions from model\n",
    "res,*_ = m(t)\n",
    "# Put the batch size back to what it was\n",
    "m[0].bs=bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nexts = torch.topk(res[-1], 10)[1]\n",
    "[TEXT.vocab.itos[o] for o in to_np(nexts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... here we do recursive predictions and generate 50 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ss,\"\\n\")\n",
    "for i in range(50):\n",
    "    n=res[-1].topk(2)[1]\n",
    "    n = n[1] if n.data[0]==0 else n[0]\n",
    "    print(TEXT.vocab.itos[n.data[0]], end=' ')\n",
    "    res,*_ = m(n[0].unsqueeze(0))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = pickle.load(open(f'{PATH}models/TEXT.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sequential=False` tells torchtext that a text field should be tokenized (in this case, we just want to store the 'positive' or 'negative' single label).\n",
    "\n",
    "`splits` is a torchtext method that creates train, test, and validation sets. The IMDB dataset is built into torchtext, so we can take advantage of that. Take a look at `lang_model-arxiv.ipynb` to see how to define your own fastai/torchtext datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall torchtext -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/pytorch/text.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cd text && python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB_LABEL = data.Field(sequential=False)\n",
    "splits = torchtext.datasets.IMDB.splits(TEXT, IMDB_LABEL, 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = splits[0].examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.label, ' '.join(t.text[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md2 = TextData.from_splits(PATH, splits, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = md2.get_model(opt_fn, 1500, bptt, emb_sz=em_sz, n_hid=nh, n_layers=nl, \n",
    "           dropout=0.1, dropouti=0.4, wdrop=0.5, dropoute=0.05, dropouth=0.3)\n",
    "m3.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "m3.load_encoder(f'adam3_20_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we're fine-tuning a pretrained model, we'll use differential learning rates, and also increase the max gradient for clipping, to allow the SGDR to work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.clip=25.\n",
    "lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.freeze_to(-1)\n",
    "m3.fit(lrs/2, 1, metrics=[accuracy])\n",
    "m3.unfreeze()\n",
    "m3.fit(lrs, 1, metrics=[accuracy], cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.fit(lrs, 7, metrics=[accuracy], cycle_len=2, cycle_save_name='imdb2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.load_cycle('imdb2', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.predict_with_targs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_np(*m3.predict_with_targs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A recent paper from Bradbury et al, [Learned in translation: contextualized word vectors](https://einstein.ai/research/learned-in-translation-contextualized-word-vectors), has a handy summary of the latest academic research in solving this IMDB sentiment analysis problem. Many of the latest algorithms shown are tuned for this specific problem.\n",
    "\n",
    "![image.png](images/paper.png)\n",
    "\n",
    "As you see, we just got a new state of the art result in sentiment analysis, decreasing the error from 5.9% to 5.5%! You should be able to get similarly world-class results on other NLP classification problems using the same basic steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
